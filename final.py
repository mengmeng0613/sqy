# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import jieba
import requests
import streamlit as st
from streamlit_echarts import st_echarts
from collections import Counter
from streamlit.logger import get_logger
import re
import string

LOGGER = get_logger(__name__)


# æ¸…ç†æ–‡æœ¬å‡½æ•°
def preprocess_text(text):
    text = re.sub(r'\s+', '', text)  # å»é™¤ç©ºç™½å­—ç¬¦
    text = re.sub(r'[\n\r]', '', text)  # å»é™¤æ¢è¡Œç¬¦
    return text.strip()


# åˆ†è¯å‡½æ•°
def word_segmentation(text):
    stopwords = set(
        ['çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ', 'ä»¬', 'è¿™', 'é‚£', 'ä¹‹', 'ä¸', 'å’Œ', 'æˆ–', 'è™½ç„¶', 'ä½†æ˜¯', 'ç„¶è€Œ', 'å› æ­¤'])
    text = re.sub(r'[^\w\s]', '', text)  # å»é™¤æ ‡ç‚¹ç¬¦å·
    words = jieba.lcut(text)
    return [word for word in words if word not in stopwords]


# ç§»é™¤æ ‡ç‚¹å’Œæ•°å­—
def remove_noise(text):
    text = re.sub(r'[' + string.punctuation + ']+', '', text)
    return re.sub(r'\d+', '', text)


# æå–æ­£æ–‡æ–‡æœ¬
def extract_main_text(html):
    from bs4 import BeautifulSoup
    soup = BeautifulSoup(html, 'html.parser')
    return soup.get_text()


# è¯»å–æ–‡æœ¬æ–‡ä»¶ç¤ºä¾‹
def display_text_file():
    st.write('ç¤ºä¾‹: è¯»å–æ–‡æœ¬æ–‡ä»¶å†…å®¹')
    from pathlib import Path
    file_path = Path(__file__).parent / "example.txt"
    if file_path.is_file():
        with open(file_path, 'r') as f:
            content = f.read()
            st.write(content)
    else:
        st.write("æ–‡ä»¶æœªæ‰¾åˆ°")


# è¿è¡Œä¸»ç¨‹åº
def main():
    st.set_page_config(
        page_title="æ–‡æœ¬å¤„ç†ç¤ºä¾‹",
        page_icon="ğŸ“",
    )

    st.title("æ¬¢è¿ä½¿ç”¨ Streamlit æ–‡æœ¬å¤„ç†ç¤ºä¾‹ ğŸ“")

    url = st.text_input('è¯·è¾“å…¥ URL:')

    if url:
        response = requests.get(url)
        response.encoding = 'utf-8'
        html_content = response.text

        text = extract_main_text(html_content)
        text = remove_noise(text)
        text = preprocess_text(text)
        words = word_segmentation(text)
        word_count = Counter(words)

        most_common_words = word_count.most_common(20)

        chart_options = {
            "tooltip": {"trigger": 'item', "formatter": '{b} : {c}'},
            "xAxis": [{
                "type": "category",
                "data": [word for word, count in most_common_words],
                "axisLabel": {"interval": 0, "rotate": 45}
            }],
            "yAxis": [{"type": "value"}],
            "series": [{
                "type": "bar",
                "data": [count for word, count in most_common_words]
            }]
        }

        st_echarts(chart_options, height='500px')

    display_text_file()


if __name__ == "__main__":
    main()


